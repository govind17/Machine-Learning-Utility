{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Utility.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOV4Zrm2vJgwbtOW43ZEU0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govind17/Machine-Learning-Utility/blob/main/ML_Utility.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4XXfLTH1Foe"
      },
      "source": [
        "Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtW2zVQ315sx"
      },
      "source": [
        "#Mean and standard Deviation\n",
        "# we see it was standard scaled, most likely, if we concat train and test, we will get exact mean=1, and std 1 \n",
        "print 'Mean:', train.x8.mean()\n",
        "print 'std:', train.x8.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dru_Dil2K7w"
      },
      "source": [
        "#To see the counts to check repeated values\n",
        "train.x8.value_counts().head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Ru4qaq05uV"
      },
      "source": [
        "#Label encoder codes\n",
        "for c in train.columns[train.dtypes == 'object']:\n",
        "    X[c] = X[c].factorize()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6itSGtv6J_t"
      },
      "source": [
        "#Re-scaling\n",
        "# It's very hard to work with scaled feature, so let's try to scale them back\n",
        "# Let's first take a look at difference between neighbouring values in x8\n",
        "# And we see that it has a lot of repeated values\n",
        "train.x8.value_counts().head(15)\n",
        "# It's very hard to work with scaled feature, so let's try to scale them back\n",
        "x8_unique = train.x8.unique()\n",
        "x8_unique_sorted = np.sort(x8_unique)                      \n",
        "np.diff(x8_unique_sorted)  #difference between neighbouring values in x8 - 0.04332159 (mostly)\n",
        "''' The data is scaled, so we don't know what was the diff value for the original feature but let's assume it was 1.0\n",
        "Let's devide all the numbers by 0.04332159 to get the right scaling note, that feature will still have zero mean'''\n",
        "np.diff(x8_unique_sorted/0.04332159)\n",
        "(train.x8/0.04332159).head(10)   # Ok, now we see .102468 in every value\n",
        "# this looks like a part of a mean that was subtracted during standard scaling\n",
        "# If we subtract it, the values become almost integers\n",
        "(train.x8/0.04332159 - .102468).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITCakLaW1SVV"
      },
      "source": [
        "Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y9mUBFQ1QFP"
      },
      "source": [
        "#RandomforestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx7Hw2XS1hEY"
      },
      "source": [
        "Post Model Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQQwWdQd1l38"
      },
      "source": [
        "#Feature importance plot(After RandomForestClassifier)\n",
        "plt.plot(rf.feature_importances_)\n",
        "plt.xticks(np.arange(X.shape[1]), X.columns.tolist(), rotation=90);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}